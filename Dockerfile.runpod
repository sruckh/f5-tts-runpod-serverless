# F5-TTS RunPod Serverless Dockerfile - Optimized Architecture
# ================================================================
# 
# This Dockerfile implements proper serverless optimization:
# - Models pre-loaded during build time
# - flash_attn installed during build (not runtime)
# - Optimized storage paths using /tmp
# - Minimal runtime dependencies
# - Fast cold start performance

FROM ghcr.io/swivid/f5-tts:main

# Set working directory
WORKDIR /app

# =============================================================================
# BUILD-TIME OPTIMIZATION: Install flash_attn
# =============================================================================

# Install flash_attn with specific wheel for Python 3.11 + CUDA 12.x compatibility
# This prevents runtime installation and disk space issues
RUN echo "⚡ Installing flash_attn during build time for optimal performance..." && \
    pip install --no-cache-dir \
    https://github.com/Dao-AILab/flash-attention/releases/download/v2.8.0.post2/flash_attn-2.8.0.post2+cu12torch2.4cxx11abiFALSE-cp311-cp311-linux_x86_64.whl

# Verify flash_attn installation
RUN python -c "import flash_attn; print('✅ flash_attn installed successfully')" || \
    (echo "❌ flash_attn installation failed" && exit 1)

# Models will be loaded from /runpod-volume at runtime, not during build.

# =============================================================================
# SERVERLESS DEPENDENCIES
# =============================================================================

# Install minimal additional dependencies for RunPod serverless
RUN pip install --no-cache-dir \
    runpod \
    boto3 \
    requests \
    librosa \
    soundfile \
    "transformers>=4.48.1"

# =============================================================================
# APPLICATION CODE
# =============================================================================

# Copy optimized serverless handler and utilities
COPY runpod-handler.py /app/runpod-handler.py
COPY s3_utils.py /app/s3_utils.py

# =============================================================================
# RUNTIME OPTIMIZATION
# =============================================================================

# Set optimal environment variables for serverless performance
ENV PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
ENV CUDA_VISIBLE_DEVICES=0

# Disable unnecessary HuggingFace features for faster startup
ENV HF_HUB_DISABLE_PROGRESS_BARS=1
ENV HF_HUB_DISABLE_SYMLINKS_WARNING=1
ENV HF_HUB_DISABLE_EXPERIMENTAL_WARNING=1

# Set Python optimization flags
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1

# =============================================================================
# CONTAINER STARTUP
# =============================================================================



# Simple startup command - no initialization scripts needed
# Models are pre-loaded, flash_attn is installed, ready to serve
CMD ["python", "-u", "/app/runpod-handler.py"]