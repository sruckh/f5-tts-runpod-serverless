#!/usr/bin/env python3
"""
WhisperX Engine for RunPod Serverless

Handles WhisperX model loading and word-level timing generation
with forced alignment for accurate timestamps.
"""

import os
import sys
import logging
import torch
import time
from pathlib import Path
from typing import Optional, Union, List, Dict, Any

# Add container app path
sys.path.append('/app')

try:
    from setup_network_venv import (  # config.py
        WHISPERX_MODELS_PATH, TEMP_PATH, WHISPERX_MODEL, DEFAULT_BATCH_SIZE, DEFAULT_COMPUTE_TYPE
    )
except ImportError:
    WHISPERX_MODELS_PATH = Path("/runpod-volume/f5tts/models/whisperx")
    TEMP_PATH = Path("/runpod-volume/f5tts/temp")
    WHISPERX_MODEL = "large-v2"
    DEFAULT_BATCH_SIZE = 16
    DEFAULT_COMPUTE_TYPE = "float16"

# Setup logging
logger = logging.getLogger(__name__)

class WhisperXEngine:
    """WhisperX model engine for word-level timing generation."""
    
    def __init__(
        self, 
        model_name: str = WHISPERX_MODEL,
        batch_size: int = DEFAULT_BATCH_SIZE,
        compute_type: str = DEFAULT_COMPUTE_TYPE
    ):
        """
        Initialize WhisperX engine.
        
        Args:
            model_name: WhisperX model name
            batch_size: Batch size for inference
            compute_type: Compute type (float16, float32, int8)
        """
        self.model_name = model_name
        self.batch_size = batch_size
        self.compute_type = compute_type
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # Model components
        self.transcription_model = None
        self.alignment_model = None
        self.diarization_model = None
        
        # Model cache paths
        self.model_dir = WHISPERX_MODELS_PATH
        self.model_dir.mkdir(parents=True, exist_ok=True)
        
        # Performance tracking
        self.model_load_time = None
        self.last_process_time = None
        
        logger.info(f"WhisperX Engine initialized: {model_name} on {self.device}")
    
    def load_models(self):
        """Load WhisperX models with caching."""
        try:
            if self.transcription_model is not None:
                logger.info("WhisperX models already loaded - using cached versions")
                return
                
            start_time = time.time()
            logger.info(f"Loading WhisperX models: {self.model_name}")
            
            # Import WhisperX modules (only available after environment setup)
            try:
                import whisperx
            except ImportError as e:
                logger.error(f"WhisperX import failed: {e}")
                raise RuntimeError("WhisperX not available - check environment setup")
            
            # Load transcription model
            logger.info("Loading WhisperX transcription model...")
            self.transcription_model = whisperx.load_model(
                self.model_name,
                device=self.device,
                compute_type=self.compute_type,
                download_root=str(self.model_dir)
            )
            
            logger.info("WhisperX models loaded successfully")
            self.model_load_time = time.time() - start_time
            
        except Exception as e:
            logger.error(f"Failed to load WhisperX models: {e}")
            raise
    
    def load_alignment_model(self, language_code: str = "en"):
        """
        Load alignment model for specific language.
        
        Args:
            language_code: Language code (e.g., 'en', 'fr', 'de')
        """
        try:
            if self.alignment_model is not None:
                logger.info("Alignment model already loaded")
                return
                
            logger.info(f"Loading alignment model for language: {language_code}")
            
            import whisperx
            
            # Load alignment model
            self.alignment_model, self.alignment_metadata = whisperx.load_align_model(
                language_code=language_code,
                device=self.device
            )
            
            logger.info("Alignment model loaded successfully")
            
        except Exception as e:
            logger.error(f"Failed to load alignment model: {e}")
            raise
    
    def transcribe_audio(self, audio_path: Union[str, Path]) -> Dict[str, Any]:
        """
        Transcribe audio using WhisperX.
        
        Args:
            audio_path: Path to audio file
            
        Returns:
            Transcription result with segments
        """
        try:
            audio_path = Path(audio_path)
            if not audio_path.exists():
                raise FileNotFoundError(f"Audio file not found: {audio_path}")
            
            logger.info(f"Transcribing audio: {audio_path}")
            
            # Ensure transcription model is loaded
            if self.transcription_model is None:
                self.load_models()
            
            import whisperx
            
            # Load audio
            audio = whisperx.load_audio(str(audio_path))
            
            # Transcribe
            logger.info("Running WhisperX transcription...")
            result = self.transcription_model.transcribe(
                audio, 
                batch_size=self.batch_size
            )
            
            logger.info(f"Transcription completed - {len(result['segments'])} segments")
            return result
            
        except Exception as e:
            logger.error(f"Failed to transcribe audio: {e}")
            raise
    
    def align_transcription(
        self, 
        segments: List[Dict], 
        audio_path: Union[str, Path],
        language_code: str = "en"
    ) -> Dict[str, Any]:
        """
        Perform forced alignment for accurate word-level timestamps.
        
        Args:
            segments: Transcription segments
            audio_path: Path to audio file
            language_code: Language code
            
        Returns:
            Aligned result with word-level timestamps
        """
        try:
            logger.info("Performing forced alignment for word-level timestamps...")
            
            # Load alignment model if needed
            if self.alignment_model is None:
                self.load_alignment_model(language_code)
            
            import whisperx
            
            # Load audio for alignment
            audio = whisperx.load_audio(str(audio_path))
            
            # Perform alignment
            aligned_result = whisperx.align(
                segments,
                self.alignment_model,
                self.alignment_metadata,
                audio,
                self.device,
                return_char_alignments=False
            )
            
            logger.info("Forced alignment completed")
            return aligned_result
            
        except Exception as e:
            logger.error(f"Failed to align transcription: {e}")
            raise
    
    def generate_word_timings(
        self, 
        audio_path: Union[str, Path], 
        expected_text: Optional[str] = None,
        language_code: str = "en"
    ) -> List[Dict[str, Any]]:
        """
        Generate word-level timings for audio.
        
        Args:
            audio_path: Path to audio file
            expected_text: Expected text (for validation)
            language_code: Language code
            
        Returns:
            List of word timing dictionaries
        """
        try:
            start_time = time.time()
            logger.info(f"Generating word-level timings for: {audio_path}")
            
            # Step 1: Transcribe audio
            transcription_result = self.transcribe_audio(audio_path)
            
            # Step 2: Perform forced alignment
            aligned_result = self.align_transcription(
                transcription_result["segments"],
                audio_path,
                language_code
            )
            
            # Step 3: Extract word timings
            word_timings = []
            
            for segment in aligned_result.get("segments", []):
                if "words" in segment:
                    for word_info in segment["words"]:
                        word_timing = {
                            "word": word_info.get("word", ""),
                            "start": word_info.get("start", 0.0),
                            "end": word_info.get("end", 0.0),
                            "confidence": word_info.get("score", 0.0)
                        }
                        word_timings.append(word_timing)
            
            # Performance tracking
            process_time = time.time() - start_time
            self.last_process_time = process_time
            
            logger.info(f"Generated {len(word_timings)} word timings in {process_time:.2f}s")
            
            # Validate against expected text if provided
            if expected_text:
                self._validate_timings(word_timings, expected_text)
            
            return word_timings
            
        except Exception as e:
            logger.error(f"Failed to generate word timings: {e}")
            raise
    
    def _validate_timings(self, word_timings: List[Dict], expected_text: str):
        """Validate word timings against expected text."""
        try:
            # Extract words from timings
            timing_words = [timing["word"].strip() for timing in word_timings]
            timing_text = " ".join(timing_words).lower()
            
            # Simple validation - check if texts are similar
            expected_lower = expected_text.lower()
            
            # Calculate similarity (simple word overlap)
            timing_words_set = set(timing_text.split())
            expected_words_set = set(expected_lower.split())
            
            if timing_words_set and expected_words_set:
                overlap = len(timing_words_set & expected_words_set)
                total = len(expected_words_set)
                similarity = overlap / total if total > 0 else 0.0
                
                logger.info(f"Text similarity: {similarity:.2f}")
                
                if similarity < 0.5:
                    logger.warning(f"Low similarity between expected and transcribed text")
            
        except Exception as e:
            logger.warning(f"Text validation failed: {e}")
    
    def get_model_info(self) -> Dict[str, Any]:
        """Get information about loaded models."""
        return {
            "model_name": self.model_name,
            "batch_size": self.batch_size,
            "compute_type": self.compute_type,
            "device": self.device,
            "transcription_model_loaded": self.transcription_model is not None,
            "alignment_model_loaded": self.alignment_model is not None,
            "model_load_time": self.model_load_time,
            "last_process_time": self.last_process_time
        }
    
    def cleanup(self):
        """Clean up models and free memory."""
        try:
            if self.transcription_model is not None:
                del self.transcription_model
                self.transcription_model = None
                
            if self.alignment_model is not None:
                del self.alignment_model
                self.alignment_model = None
                
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                
            logger.info("WhisperX engine cleaned up")
            
        except Exception as e:
            logger.error(f"Failed to cleanup WhisperX engine: {e}")

# Global engine instance for warm loading
_whisperx_engine = None

def get_whisperx_engine() -> WhisperXEngine:
    """Get global WhisperX engine instance."""
    global _whisperx_engine
    if _whisperx_engine is None:
        _whisperx_engine = WhisperXEngine()
    return _whisperx_engine

def generate_word_timings(audio_path: Union[str, Path], expected_text: str = None) -> List[Dict[str, Any]]:
    """
    Convenience function for word timing generation.
    
    Args:
        audio_path: Path to audio file
        expected_text: Expected text for validation
        
    Returns:
        List of word timing dictionaries
    """
    engine = get_whisperx_engine()
    return engine.generate_word_timings(audio_path, expected_text)

# Test function
if __name__ == "__main__":
    """Test WhisperX engine."""
    try:
        engine = WhisperXEngine()
        logger.info("WhisperX engine test passed")
        
        # Print model info
        info = engine.get_model_info()
        for key, value in info.items():
            logger.info(f"{key}: {value}")
            
    except Exception as e:
        logger.error(f"WhisperX engine test failed: {e}")
        sys.exit(1)#!/usr/bin/env python3
"""
WhisperX Engine for RunPod Serverless

Handles WhisperX model loading and word-level timing generation
with forced alignment for accurate timestamps.
"""

import os
import sys
import logging
import torch
import time
from pathlib import Path
from typing import Optional, Union, List, Dict, Any

# Add container app path
sys.path.append('/app')

try:
    from setup_network_venv import (  # config.py
        WHISPERX_MODELS_PATH, TEMP_PATH, WHISPERX_MODEL, DEFAULT_BATCH_SIZE, DEFAULT_COMPUTE_TYPE
    )
except ImportError:
    WHISPERX_MODELS_PATH = Path("/runpod-volume/f5tts/models/whisperx")
    TEMP_PATH = Path("/runpod-volume/f5tts/temp")
    WHISPERX_MODEL = "large-v2"
    DEFAULT_BATCH_SIZE = 16
    DEFAULT_COMPUTE_TYPE = "float16"

# Setup logging
logger = logging.getLogger(__name__)

class WhisperXEngine:
    """WhisperX model engine for word-level timing generation."""
    
    def __init__(
        self, 
        model_name: str = WHISPERX_MODEL,
        batch_size: int = DEFAULT_BATCH_SIZE,
        compute_type: str = DEFAULT_COMPUTE_TYPE
    ):
        """
        Initialize WhisperX engine.
        
        Args:
            model_name: WhisperX model name
            batch_size: Batch size for inference
            compute_type: Compute type (float16, float32, int8)
        """
        self.model_name = model_name
        self.batch_size = batch_size
        self.compute_type = compute_type
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # Model components
        self.transcription_model = None
        self.alignment_model = None
        self.diarization_model = None
        
        # Model cache paths
        self.model_dir = WHISPERX_MODELS_PATH
        self.model_dir.mkdir(parents=True, exist_ok=True)
        
        # Performance tracking
        self.model_load_time = None
        self.last_process_time = None
        
        logger.info(f"WhisperX Engine initialized: {model_name} on {self.device}")
    
    def load_models(self):
        """Load WhisperX models with caching."""
        try:
            if self.transcription_model is not None:
                logger.info("WhisperX models already loaded - using cached versions")
                return
                
            start_time = time.time()
            logger.info(f"Loading WhisperX models: {self.model_name}")
            
            # Import WhisperX modules (only available after environment setup)
            try:
                import whisperx
            except ImportError as e:
                logger.error(f"WhisperX import failed: {e}")
                raise RuntimeError("WhisperX not available - check environment setup")
            
            # Load transcription model
            logger.info("Loading WhisperX transcription model...")
            self.transcription_model = whisperx.load_model(
                self.model_name,
                device=self.device,
                compute_type=self.compute_type,
                download_root=str(self.model_dir)
            )
            
            logger.info("WhisperX models loaded successfully")
            self.model_load_time = time.time() - start_time
            
        except Exception as e:
            logger.error(f"Failed to load WhisperX models: {e}")
            raise
    
    def load_alignment_model(self, language_code: str = "en"):
        """
        Load alignment model for specific language.
        
        Args:
            language_code: Language code (e.g., 'en', 'fr', 'de')
        """
        try:
            if self.alignment_model is not None:
                logger.info("Alignment model already loaded")
                return
                
            logger.info(f"Loading alignment model for language: {language_code}")
            
            import whisperx
            
            # Load alignment model
            self.alignment_model, self.alignment_metadata = whisperx.load_align_model(
                language_code=language_code,
                device=self.device
            )
            
            logger.info("Alignment model loaded successfully")
            
        except Exception as e:
            logger.error(f"Failed to load alignment model: {e}")
            raise
    
    def transcribe_audio(self, audio_path: Union[str, Path]) -> Dict[str, Any]:
        """
        Transcribe audio using WhisperX.
        
        Args:
            audio_path: Path to audio file
            
        Returns:
            Transcription result with segments
        """
        try:
            audio_path = Path(audio_path)
            if not audio_path.exists():
                raise FileNotFoundError(f"Audio file not found: {audio_path}")
            
            logger.info(f"Transcribing audio: {audio_path}")
            
            # Ensure transcription model is loaded
            if self.transcription_model is None:
                self.load_models()
            
            import whisperx
            
            # Load audio
            audio = whisperx.load_audio(str(audio_path))
            
            # Transcribe
            logger.info("Running WhisperX transcription...")
            result = self.transcription_model.transcribe(
                audio, 
                batch_size=self.batch_size
            )
            
            logger.info(f"Transcription completed - {len(result['segments'])} segments")
            return result
            
        except Exception as e:
            logger.error(f"Failed to transcribe audio: {e}")
            raise
    
    def align_transcription(
        self, 
        segments: List[Dict], 
        audio_path: Union[str, Path],
        language_code: str = "en"
    ) -> Dict[str, Any]:
        """
        Perform forced alignment for accurate word-level timestamps.
        
        Args:
            segments: Transcription segments
            audio_path: Path to audio file
            language_code: Language code
            
        Returns:
            Aligned result with word-level timestamps
        """
        try:
            logger.info("Performing forced alignment for word-level timestamps...")
            
            # Load alignment model if needed
            if self.alignment_model is None:
                self.load_alignment_model(language_code)
            
            import whisperx
            
            # Load audio for alignment
            audio = whisperx.load_audio(str(audio_path))
            
            # Perform alignment
            aligned_result = whisperx.align(
                segments,
                self.alignment_model,
                self.alignment_metadata,
                audio,
                self.device,
                return_char_alignments=False
            )
            
            logger.info("Forced alignment completed")
            return aligned_result
            
        except Exception as e:
            logger.error(f"Failed to align transcription: {e}")
            raise
    
    def generate_word_timings(
        self, 
        audio_path: Union[str, Path], 
        expected_text: Optional[str] = None,
        language_code: str = "en"
    ) -> List[Dict[str, Any]]:
        """
        Generate word-level timings for audio.
        
        Args:
            audio_path: Path to audio file
            expected_text: Expected text (for validation)
            language_code: Language code
            
        Returns:
            List of word timing dictionaries
        """
        try:
            start_time = time.time()
            logger.info(f"Generating word-level timings for: {audio_path}")
            
            # Step 1: Transcribe audio
            transcription_result = self.transcribe_audio(audio_path)
            
            # Step 2: Perform forced alignment
            aligned_result = self.align_transcription(
                transcription_result["segments"],
                audio_path,
                language_code
            )
            
            # Step 3: Extract word timings
            word_timings = []
            
            for segment in aligned_result.get("segments", []):
                if "words" in segment:
                    for word_info in segment["words"]:
                        word_timing = {
                            "word": word_info.get("word", ""),
                            "start": word_info.get("start", 0.0),
                            "end": word_info.get("end", 0.0),
                            "confidence": word_info.get("score", 0.0)
                        }
                        word_timings.append(word_timing)
            
            # Performance tracking
            process_time = time.time() - start_time
            self.last_process_time = process_time
            
            logger.info(f"Generated {len(word_timings)} word timings in {process_time:.2f}s")
            
            # Validate against expected text if provided
            if expected_text:
                self._validate_timings(word_timings, expected_text)
            
            return word_timings
            
        except Exception as e:
            logger.error(f"Failed to generate word timings: {e}")
            raise
    
    def _validate_timings(self, word_timings: List[Dict], expected_text: str):
        """Validate word timings against expected text."""
        try:
            # Extract words from timings
            timing_words = [timing["word"].strip() for timing in word_timings]
            timing_text = " ".join(timing_words).lower()
            
            # Simple validation - check if texts are similar
            expected_lower = expected_text.lower()
            
            # Calculate similarity (simple word overlap)
            timing_words_set = set(timing_text.split())
            expected_words_set = set(expected_lower.split())
            
            if timing_words_set and expected_words_set:
                overlap = len(timing_words_set & expected_words_set)
                total = len(expected_words_set)
                similarity = overlap / total if total > 0 else 0.0
                
                logger.info(f"Text similarity: {similarity:.2f}")
                
                if similarity < 0.5:
                    logger.warning(f"Low similarity between expected and transcribed text")
            
        except Exception as e:
            logger.warning(f"Text validation failed: {e}")
    
    def get_model_info(self) -> Dict[str, Any]:
        """Get information about loaded models."""
        return {
            "model_name": self.model_name,
            "batch_size": self.batch_size,
            "compute_type": self.compute_type,
            "device": self.device,
            "transcription_model_loaded": self.transcription_model is not None,
            "alignment_model_loaded": self.alignment_model is not None,
            "model_load_time": self.model_load_time,
            "last_process_time": self.last_process_time
        }
    
    def cleanup(self):
        """Clean up models and free memory."""
        try:
            if self.transcription_model is not None:
                del self.transcription_model
                self.transcription_model = None
                
            if self.alignment_model is not None:
                del self.alignment_model
                self.alignment_model = None
                
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                
            logger.info("WhisperX engine cleaned up")
            
        except Exception as e:
            logger.error(f"Failed to cleanup WhisperX engine: {e}")

# Global engine instance for warm loading
_whisperx_engine = None

def get_whisperx_engine() -> WhisperXEngine:
    """Get global WhisperX engine instance."""
    global _whisperx_engine
    if _whisperx_engine is None:
        _whisperx_engine = WhisperXEngine()
    return _whisperx_engine

def generate_word_timings(audio_path: Union[str, Path], expected_text: str = None) -> List[Dict[str, Any]]:
    """
    Convenience function for word timing generation.
    
    Args:
        audio_path: Path to audio file
        expected_text: Expected text for validation
        
    Returns:
        List of word timing dictionaries
    """
    engine = get_whisperx_engine()
    return engine.generate_word_timings(audio_path, expected_text)

# Test function
if __name__ == "__main__":
    """Test WhisperX engine."""
    try:
        engine = WhisperXEngine()
        logger.info("WhisperX engine test passed")
        
        # Print model info
        info = engine.get_model_info()
        for key, value in info.items():
            logger.info(f"{key}: {value}")
            
    except Exception as e:
        logger.error(f"WhisperX engine test failed: {e}")
        sys.exit(1)